{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "12F6qa3Z3Fst"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "import warnings\n",
    "import os\n",
    "import keras\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "YzjNM3xI3Fs0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/segmentation_models\r\n",
      "  Cloning https://github.com/qubvel/segmentation_models to /tmp/pip-req-build-5n2c9aem\r\n",
      "Requirement already satisfied: keras>=2.2.0 in /opt/conda/lib/python3.6/site-packages (from segmentation-models==0.2.0) (2.2.4)\r\n",
      "Requirement already satisfied: keras_applications>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from segmentation-models==0.2.0) (1.0.7)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from segmentation-models==0.2.0) (0.15.0)\r\n",
      "Collecting image-classifiers==0.2.0 (from segmentation-models==0.2.0)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/32/a1e74e03f74506d1e4b46bb2732ca5a7b18ac52a36b5e3547e63537ce74c/image_classifiers-0.2.0-py2.py3-none-any.whl (76kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 5.2MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models==0.2.0) (2.9.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models==0.2.0) (1.0.9)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models==0.2.0) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models==0.2.0) (1.12.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models==0.2.0) (1.16.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models==0.2.0) (3.12)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models==0.2.0) (2.1)\r\n",
      "Requirement already satisfied: imageio>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models==0.2.0) (2.3.0)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models==0.2.0) (3.0.3)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models==0.2.0) (5.1.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models==0.2.0) (0.5.2)\r\n",
      "Requirement already satisfied: decorator>=4.1.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->segmentation-models==0.2.0) (4.3.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.0) (2.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.0) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.0) (2.6.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.0) (1.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.0) (39.1.0)\r\n",
      "Building wheels for collected packages: segmentation-models\r\n",
      "  Building wheel for segmentation-models (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-a0gpbu0g/wheels/49/cf/46/cbb4bb64518c402aea99df9d466f1081450597e653256bbcf4\r\n",
      "Successfully built segmentation-models\r\n",
      "Installing collected packages: image-classifiers, segmentation-models\r\n",
      "Successfully installed image-classifiers-0.2.0 segmentation-models-0.2.0\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting keras-adabound\r\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/83/81b9e73aa089b0646feaacf911cd22cc4d5ea0374ef03609c35004b025e7/keras-adabound-0.4.1.tar.gz\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from keras-adabound) (1.16.3)\r\n",
      "Requirement already satisfied: Keras in /opt/conda/lib/python3.6/site-packages (from keras-adabound) (2.2.4)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-adabound) (1.12.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras->keras-adabound) (3.12)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-adabound) (1.0.7)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-adabound) (1.1.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-adabound) (1.0.9)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras->keras-adabound) (2.9.0)\r\n",
      "Building wheels for collected packages: keras-adabound\r\n",
      "  Building wheel for keras-adabound (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/26/fb/78/f6aa020cb8f098fecdf1e9043a9bb259c8414692d4225c6183\r\n",
      "Successfully built keras-adabound\r\n",
      "Installing collected packages: keras-adabound\r\n",
      "Successfully installed keras-adabound-0.4.1\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: segmentation-models in /opt/conda/lib/python3.6/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: keras>=2.2.0 in /opt/conda/lib/python3.6/site-packages (from segmentation-models) (2.2.4)\r\n",
      "Requirement already satisfied: image-classifiers==0.2.0 in /opt/conda/lib/python3.6/site-packages (from segmentation-models) (0.2.0)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from segmentation-models) (0.15.0)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from segmentation-models) (1.0.7)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (2.9.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (1.12.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (1.16.3)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (1.0.9)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (3.12)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (5.1.0)\r\n",
      "Requirement already satisfied: imageio>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (2.3.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (0.5.2)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (2.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (3.0.3)\r\n",
      "Requirement already satisfied: decorator>=4.1.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->segmentation-models) (4.3.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (2.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (1.0.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (2.6.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (39.1.0)\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/qubvel/segmentation_models\n",
    "#https://pypi.org/project/keras-adabound/\n",
    "#https://segmentation-models.readthedocs.io/en/latest/\n",
    "!pip install git+https://github.com/qubvel/segmentation_models\n",
    "!pip install keras-adabound\n",
    "!pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-5wTBJ43Fs4",
    "outputId": "81087b0e-a7bd-4b07-d564-08c02e261e9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/classification_models/resnext/__init__.py:4: UserWarning: Current ResNext models are deprecated, use keras.applications ResNeXt models\n",
      "  warnings.warn('Current ResNext models are deprecated, '\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.metrics import f_score, iou_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yceA-X653Fs-"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VY39qdVJ3Fs_"
   },
   "outputs": [],
   "source": [
    "train_path = '../input/train_v2/'\n",
    "test_path = '../input/test_v2/'\n",
    "data = pd.read_csv('../input/train_ship_segmentations_v2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lWvDysu3FtB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "from skimage.morphology import binary_opening, disk, label\n",
    "import gc; gc.enable() # memory is tight\n",
    "\n",
    "train_image_dir = train_path\n",
    "test_image_dir = test_path\n",
    "\n",
    "def multi_rle_encode(img, **kwargs):\n",
    "    '''\n",
    "    Encode connected regions as separated masks\n",
    "    '''\n",
    "    labels = label(img)\n",
    "    if img.ndim > 2:\n",
    "        return [rle_encode(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n",
    "    else:\n",
    "        return [rle_encode(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img, min_max_threshold=1e-3, max_mean_threshold=None):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    if np.max(img) < min_max_threshold:\n",
    "        return '' ## no need to encode if it's all zeros\n",
    "    if max_mean_threshold and np.mean(img) > max_mean_threshold:\n",
    "        return '' ## ignore overfilled mask\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    if type(in_mask_list) == 'float':\n",
    "        return all_masks\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return all_masks\n",
    "\n",
    "def masks_as_color(in_mask_list):\n",
    "    # Take the individual ship masks and create a color mask array for each ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.float)\n",
    "    scale = lambda x: (len(in_mask_list)+x+1) / (len(in_mask_list)*2) ## scale the heatmap image to shift \n",
    "    for i,mask in enumerate(in_mask_list):\n",
    "        if isinstance(mask, str):\n",
    "            all_masks[:,:] += scale(i) * rle_decode(mask)\n",
    "    return all_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oWJeVULN3FtD"
   },
   "source": [
    "## Data Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-nRkffc3FtD",
    "outputId": "7d1f5d22-3e9e-469f-e2cf-4cbb253bd39e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120226, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk]\n",
    "val = data[~msk]\n",
    "\n",
    "train_no_ship = train[train[\"EncodedPixels\"].isnull()]\n",
    "train_with_ship = train[train[\"EncodedPixels\"].notnull()]\n",
    "train_with_ship['ship_count'] = train_with_ship.groupby('ImageId')['ImageId'].transform('count')\n",
    "train_with_ship['ship_count'].fillna(0,inplace=True) \n",
    "train_no_ship['ship_count'] = 0\n",
    "print(train_no_ship.shape)\n",
    "sns.distplot(train_with_ship['ship_count'],kde=False);\n",
    "\n",
    "down_sampled_no_ship = train_no_ship.sample(2000)\n",
    "balanced_train = pd.concat([down_sampled_no_ship, train_with_ship])\n",
    "#balanced_train = train_with_ship\n",
    "sns.distplot(balanced_train['ship_count'],kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39i4aqZM3FtG"
   },
   "outputs": [],
   "source": [
    "partition = {}\n",
    "partition['train'] = balanced_train['ImageId'].values\n",
    "partition['val'] = val['ImageId'].values\n",
    "#labels = dict(zip(data['ImageId'].values, data['EncodedPixels'].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZar7dxP3FtI"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZcRlfbp3FtJ"
   },
   "outputs": [],
   "source": [
    "def transform(image, rate=0.15):\n",
    "    rnd = np.random.uniform(0, 1, 5)\n",
    "    ## contrast\n",
    "    if rnd[2] < rate:\n",
    "        v_min, v_max = np.percentile(image, (0.2, 99.8))\n",
    "        image= exposure.rescale_intensity(image, in_range=(v_min, v_max))\n",
    "        \n",
    "    ## horizontal flip\n",
    "    if rnd[3] < rate:\n",
    "        image= image[:, ::-1]\n",
    "    \n",
    "    ## vertical flip\n",
    "    if rnd[4] < rate:\n",
    "        image= image[::-1, :]\n",
    "        \n",
    "    ## rotation\n",
    "    if rnd[0] < rate:\n",
    "        deg = np.random.choice(range(6, 25))\n",
    "        image= rotate(image, deg)\n",
    "    \n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tH9MgHVv3FtK"
   },
   "outputs": [],
   "source": [
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4K437Fp3FtL"
   },
   "outputs": [],
   "source": [
    "import gc \n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, data, batch_size=5, dim=(512, 512, 3), shuffle=True, resize_img = False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.resize = resize_img\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size, self.dim[0], self.dim[1], 1), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            path = os.path.join(train_path, ID)\n",
    "            image = imread(path)\n",
    "            encoded_pixels = self.data[self.data['ImageId']==ID]['EncodedPixels']\n",
    "            mask = masks_as_image(encoded_pixels)\n",
    "            if self.resize:\n",
    "                resized_x = cv2.resize(image, (self.dim[0], self.dim[1]))\n",
    "                X[i,] = transform(resized_x)/255.0\n",
    "                resized_y = cv2.resize(mask, (self.dim[0], self.dim[1]))\n",
    "                y[i] = np.reshape(resized_y, (self.dim[0], self.dim[1], 1))\n",
    "            else:\n",
    "                X[i,] = transform(image)/255.0\n",
    "                y[i] = np.reshape(mask, (self.dim[0], self.dim[1], 1))\n",
    "            gc.collect()\n",
    "        gc.collect()\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmyr-yT63FtM",
    "outputId": "2e787560-9cd4-4cf9-9d7b-097ee20539a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na = data[data['ImageId']=='00003e153.jpg']['EncodedPixels'].values[0]\n",
    "type(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rvCmaHl3FtO"
   },
   "outputs": [],
   "source": [
    "partition['train'].shape, partition['val'].shape\n",
    "partition['reduced_train'] = np.random.choice(partition['train'], 8000)\n",
    "partition['reduced_val'] = np.random.choice(partition['val'], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "auBvF68G3FtT"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "params = {'dim': (512, 512, 3),\n",
    "          'batch_size': 16,\n",
    "          'shuffle': True, \n",
    "         'resize_img':True}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "params = {'dim': (768, 512, 3),\n",
    "          'batch_size': 1,\n",
    "          'shuffle': True}\n",
    "\"\"\"\n",
    "# Generators\n",
    "\n",
    "train_gen = DataGenerator(partition['reduced_train'], data, **params)\n",
    "val_gen = DataGenerator(partition['reduced_val'], data, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4Fi-TjJ3FtZ"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint ,ReduceLROnPlateau\n",
    "\n",
    "BATCH_SIZE = params['batch_size']\n",
    "MAX_TRAIN_STEPS = 10\n",
    "steps_per_epoch = partition['reduced_train'].shape[0]//BATCH_SIZE\n",
    "validation_steps = partition['reduced_val'].shape[0]//BATCH_SIZE\n",
    "\n",
    "def f2_micro(y_true, y_pred):\n",
    "    agreement = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    total_true_positive = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    total_pred_positive = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    recall = agreement / (total_true_positive + K.epsilon())\n",
    "    precision = agreement / (total_pred_positive + K.epsilon())\n",
    "    return (1+2**2)*((precision*recall)/(2**2*precision+recall+K.epsilon()))\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='unet2.hdf5', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gszNFU_K3lcw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<__main__...., validation_data=<__main__...., steps_per_epoch=500, validation_steps=62, epochs=8, callbacks=[<keras.ca..., verbose=1, use_multiprocessing=False)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "500/500 [==============================] - 1990s 4s/step - loss: 0.7996 - f2_micro: 0.1723 - val_loss: 0.9249 - val_f2_micro: 0.1941\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92487, saving model to unet2.hdf5\n",
      "Epoch 2/8\n",
      "500/500 [==============================] - 1931s 4s/step - loss: 0.6777 - f2_micro: 0.4167 - val_loss: 0.8782 - val_f2_micro: 0.3318\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.92487 to 0.87823, saving model to unet2.hdf5\n",
      "Epoch 3/8\n",
      "500/500 [==============================] - 1924s 4s/step - loss: 0.6398 - f2_micro: 0.4626 - val_loss: 0.8757 - val_f2_micro: 0.3453\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.87823 to 0.87571, saving model to unet2.hdf5\n",
      "Epoch 4/8\n",
      "500/500 [==============================] - 1813s 4s/step - loss: 0.6262 - f2_micro: 0.4722 - val_loss: 0.8628 - val_f2_micro: 0.3997\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87571 to 0.86283, saving model to unet2.hdf5\n",
      "Epoch 5/8\n",
      "500/500 [==============================] - 1808s 4s/step - loss: 0.6067 - f2_micro: 0.4852 - val_loss: 0.8610 - val_f2_micro: 0.3849\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.86283 to 0.86099, saving model to unet2.hdf5\n",
      "Epoch 6/8\n",
      "500/500 [==============================] - 1799s 4s/step - loss: 0.6011 - f2_micro: 0.4916 - val_loss: 0.8586 - val_f2_micro: 0.4305\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.86099 to 0.85856, saving model to unet2.hdf5\n",
      "Epoch 7/8\n",
      "500/500 [==============================] - 1806s 4s/step - loss: 0.5945 - f2_micro: 0.5022 - val_loss: 0.8487 - val_f2_micro: 0.4542\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.85856 to 0.84874, saving model to unet2.hdf5\n",
      "Epoch 8/8\n",
      "500/500 [==============================] - 1799s 4s/step - loss: 0.5888 - f2_micro: 0.5015 - val_loss: 0.8625 - val_f2_micro: 0.3840\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.84874\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models import Unet\n",
    "from segmentation_models.utils import set_trainable\n",
    "from segmentation_models.losses import dice_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "from keras_adabound import AdaBound\n",
    "\n",
    "model = Unet()\n",
    "model.compile(optimizer=AdaBound(lr=1e-3, final_lr=0.1), loss=dice_loss, metrics=[f2_micro])\n",
    "hist = model.fit_generator(generator=train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    epochs=8,\n",
    "                    pickle_safe=False,\n",
    "                    callbacks=[checkpointer,reduce_lr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6G2oSMO5Xgj"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'float32' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-62f5aee5c89b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Get the dictionary containing each metric and the loss for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save it under the form of a json file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hist_dict.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'float32' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "# Save it under the form of a json file\n",
    "json.dump(hist.history, open(\"hist_dict.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fYROKpgA4Sjy"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"loss\"],label=\"training loss\")\n",
    "plt.plot(hist.history[\"val_loss\"],label=\"val loss\")\n",
    "plt.title(\"UNet 2 Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Nl2l4cyy3Fta"
   ],
   "name": "yixin_airbus.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
